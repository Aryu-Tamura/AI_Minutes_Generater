import streamlit as st
from openai import OpenAI
import whisper
import torch
from pyannote.audio import Pipeline
from pydub import AudioSegment
import tempfile
import os
from datetime import timedelta, date, datetime
from docx import Document
from docx.shared import Inches, Pt
from io import BytesIO
import json
import plotly.graph_objects as go
import logging
import sqlite3
import zipfile
import re

# -------------------------------------------------------------------
# 1. åˆæœŸè¨­å®š & ãƒ­ã‚®ãƒ³ã‚°ãƒ»DBè¨­å®š
# -------------------------------------------------------------------

st.set_page_config(layout="wide", page_title="AIäº¤æ¸‰ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")

# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', filename='app.log', filemode='a')

# Streamlitã®secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã‚€
try:
    HF_TOKEN = st.secrets["HF_TOKEN"]
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    logging.info("API keys loaded successfully.")
except FileNotFoundError:
    st.error("`.streamlit/secrets.toml`ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    logging.error("secrets.toml not found.")
    st.stop()
except KeyError as e:
    st.error(f"`secrets.toml`ã«`{e}`ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    logging.error(f"API key missing in secrets.toml: {e}")
    st.stop()

# å„ç¨®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
WHISPER_MODEL = "small"
client = OpenAI(api_key=OPENAI_API_KEY)

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
DB_FILE = "database.db"
def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''
        CREATE TABLE IF NOT EXISTS reports (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp TEXT NOT NULL,
            sales_rep TEXT NOT NULL,
            client_company TEXT NOT NULL,
            client_rep TEXT NOT NULL,
            report_date TEXT NOT NULL,
            analysis_json TEXT NOT NULL,
            report_markdown TEXT,
            cleaned_transcript TEXT
        )
    ''')
    conn.commit()
    conn.close()
    logging.info("Database initialized.")
init_db()

# -------------------------------------------------------------------
# 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®ç®¡ç†
# -------------------------------------------------------------------
def reset_creation_page_state():
    """å•†è«‡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆãƒšãƒ¼ã‚¸ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹é–¢æ•°"""
    st.session_state.analysis_stage = "initial"
    st.session_state.negotiation_info = {}
    st.session_state.analysis_data = None
    st.session_state.transcript_display = []
    st.session_state.chat_history = []
    st.session_state.report_for_display = ""
    st.session_state.uploaded_file = None
    st.session_state.current_report_id = None
    st.session_state.report_saved = False
    logging.info("Creation page state has been reset.")

if "current_page" not in st.session_state:
    st.session_state.current_page = "creation"
    reset_creation_page_state()

# -------------------------------------------------------------------
# 3. OpenAI GPT API é–¢é€£é–¢æ•°
# -------------------------------------------------------------------

def get_negotiation_analysis(transcript_text, negotiation_info):
    """
    æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ ¹æ‹ ã¨ã‚»ãƒ¼ãƒ«ã‚¹ãƒ•ãƒ­ãƒ¼ã«åŸºã¥ã„ãŸäº¤æ¸‰åˆ†æã‚’è¡Œã†é–¢æ•°ã€‚
    """
    system_prompt = """
ã‚ãªãŸã¯ã€éŠ€è¡Œæ¸‰å¤–æ‹…å½“è€…ã®ãŸã‚ã®è¶…ä¸€æµãƒã‚´ã‚·ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ã‚³ãƒ¼ãƒã§ã™ã€‚
æä¾›ã•ã‚ŒãŸå•†è«‡ã®æ–‡å­—èµ·ã“ã—ã‚’åˆ†æã—ã€æ‹…å½“è€…ã®äº¤æ¸‰ã‚¹ã‚­ãƒ«ã‚’å¤šè§’çš„ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ã‚ãªãŸã®æœ€å¤§ã®ä»»å‹™ã¯ã€è©•ä¾¡ãŒãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã«ãªã‚‰ãªã„ã‚ˆã†ã€ã™ã¹ã¦ã®è©•ä¾¡é …ç›®ã«å¯¾ã—ã¦ã€ãã®æ ¹æ‹ ã¨ãªã£ãŸä¼šè©±ä¸­ã®å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ã¦æç¤ºã™ã‚‹ã“ã¨ã§ã™ã€‚

è©•ä¾¡ã¯ã€ä»¥ä¸‹ã®**ç†æƒ³çš„ãªã‚»ãƒ¼ãƒ«ã‚¹ãƒ•ãƒ­ãƒ¼**ã‚’åŸºæº–ã«è¡Œã„ã¾ã™ã€‚
1.  **é–¢ä¿‚æ§‹ç¯‰ (Rapport Building)**: ç›¸æ‰‹ã‚’æ‰¿èªã—ã€å®‰å¿ƒã—ã¦è©±ã›ã‚‹é›°å›²æ°—ã‚’ä½œã‚‹ã€‚
2.  **èª²é¡Œç™ºè¦‹ (Problem Discovery)**: ç›¸æ‰‹ã®ç¾çŠ¶ã¨ã€ãã®èƒŒæ™¯ã«ã‚ã‚‹æœ¬è³ªçš„ãªèª²é¡Œã‚’å¼•ãå‡ºã™ã€‚
3.  **ä¾¡å€¤ææ¡ˆ (Value Proposition)**: å¼•ãå‡ºã—ãŸèª²é¡Œã«å¯¾ã—ã€è§£æ±ºç­–ã¨ãƒ—ãƒ©ã‚¹ã‚¢ãƒ«ãƒ•ã‚¡ã®ä¾¡å€¤ã‚’æç¤ºã™ã‚‹ã€‚
4.  **åˆæ„å½¢æˆã¨ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚° (Closing)**: æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ˜ç¢ºã«ã—ã€å‰å‘ããªåˆæ„ã‚’å½¢æˆã™ã‚‹ã€‚

å®Ÿéš›ã®ä¼šè©±ãŒã“ã®ç†æƒ³çš„ãªé †åºã¨è¦ç´ ã‚’ã©ã‚Œã ã‘æº€ãŸã—ã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã—ã€å®¢è¦³çš„ãªæ ¹æ‹ ã«åŸºã¥ã„ãŸã€èª°ãŒè¦‹ã¦ã‚‚ç´å¾—ã§ãã‚‹å»ºè¨­çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’JSONå½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
"""
    user_prompt = f"""
### æŒ‡ç¤º
ä»¥ä¸‹ã®å•†è«‡ã®æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ã‚ãªãŸã®è©•ä¾¡ã¨ãã®è©•ä¾¡ã«è‡³ã£ãŸ**æ ¹æ‹ ã¨ãªã‚‹ç™ºè¨€**ã‚’å¿…ãšå¼•ç”¨ã—ã¦ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§çµæœã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ã¾ãŸã€æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€è©±è€…åï¼ˆä¾‹ï¼šæ¸¡è¾ºï¼ˆéŠ€è¡Œå“¡ï¼‰ï¼‰ã‚’ç‰¹å®šã—ã€cleaned_transcriptã®speakerã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚

### åˆ†æå¯¾è±¡ã®æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿
```
{transcript_text}
```

### å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (JSON)
```json
{{
  "cleaned_transcript": [
    {{ "speaker": "ï¼ˆè©±è€…åï¼‰", "text": "ï¼ˆç™ºè¨€å†…å®¹ï¼‰", "start_time": "ï¼ˆé–‹å§‹æ™‚é–“ï¼‰" }}
  ],
  "summary_report": {{
    "overview": {{
        "date": "{negotiation_info['date']}",
        "attendees": {{
            "client_company": "{negotiation_info['client_company']}",
            "client_rep": "{negotiation_info['client_rep']} æ§˜",
            "our_company": "{negotiation_info['sales_rep']}"
        }}
    }},
    "agenda": "ï¼ˆæœ¬æ—¥ã®ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ã‚’è¦ç´„ï¼‰",
    "summary": [
        "ï¼ˆè­°è«–å…¨ä½“ã®è¦ç‚¹ã‚’å…·ä½“çš„ã«è¦ç´„ã—ãŸ1ã¤ç›®ã®ç®‡æ¡æ›¸ãï¼‰",
        "ï¼ˆè­°è«–å…¨ä½“ã®è¦ç‚¹ã‚’å…·ä½“çš„ã«è¦ç´„ã—ãŸ2ã¤ç›®ã®ç®‡æ¡æ›¸ãï¼‰",
        "ï¼ˆè­°è«–å…¨ä½“ã®è¦ç‚¹ã‚’å…·ä½“çš„ã«è¦ç´„ã—ãŸ3ã¤ç›®ã®ç®‡æ¡æ›¸ãï¼‰"
    ],
    "decisions": ["ï¼ˆæ±ºå®šäº‹é …1ï¼‰", "ï¼ˆæ±ºå®šäº‹é …2ï¼‰"],
    "todos": ["ï¼ˆæ‹…å½“è€…åï¼‰ã‚¿ã‚¹ã‚¯1", "ï¼ˆæ‹…å½“è€…åï¼‰ã‚¿ã‚¹ã‚¯2"],
    "concerns": ["ï¼ˆæ‡¸å¿µäº‹é …1ï¼‰"]
  }},
  "overall_score": {{
    "score": "ï¼ˆ0ã€œ100ç‚¹ã®æ•´æ•°ï¼‰",
    "summary": "ï¼ˆã“ã®äº¤æ¸‰å…¨ä½“ã®ç·è©•ï¼‰"
  }},
  "flow_narrative_analysis": {{
    "title": "ï¼ˆä»Šå›ã®äº¤æ¸‰å…¨ä½“ã®æµã‚Œã«å¯¾ã™ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ï¼‰",
    "narrative_comment": "ï¼ˆç†æƒ³çš„ãªã‚»ãƒ¼ãƒ«ã‚¹ãƒ•ãƒ­ãƒ¼ã«æ²¿ã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã®ç·è©•ã€‚ç‰©èªã®ã‚ˆã†ã«è§£èª¬ã™ã‚‹ï¼‰",
    "strength_point": "ï¼ˆç‰¹ã«æµã‚ŒãŒè‰¯ã‹ã£ãŸç‚¹ã€ã¾ãŸã¯è»¢æ›ç‚¹ã¨ãªã£ãŸç™ºè¨€ï¼‰",
    "weakness_point": "ï¼ˆæµã‚ŒãŒæ»ã£ãŸã‚Šã€é †åºãŒä¸é©åˆ‡ã ã£ãŸç‚¹ï¼‰"
  }},
  "sales_flow_assessment": {{
    "rapport_building": {{ "score": "A", "comment": "...", "evidence_quote": "..." }},
    "problem_discovery": {{ "score": "B", "comment": "...", "evidence_quote": "..." }},
    "value_addition": {{ "score": "C", "comment": "...", "evidence_quote": "..." }},
    "closing": {{ "score": "D", "comment": "...", "evidence_quote": "..." }}
  }},
  "key_learning_point": {{
    "title": "ï¼ˆä»Šå›ã®äº¤æ¸‰ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹æœ€ã‚‚é‡è¦ãªå­¦ã³ï¼‰",
    "description": "ï¼ˆå­¦ã³ã®è©³ç´°ãªèª¬æ˜ï¼‰",
    "evidence_quote": "ï¼ˆãã®å­¦ã³ã®æ ¹æ‹ ã¨ãªã£ãŸè±¡å¾´çš„ãªä¼šè©±ãƒ‘ãƒ¼ãƒˆã‚’å¼•ç”¨ï¼‰"
  }}
}}
```
"""
    try:
        logging.info("Requesting negotiation analysis from GPT-4o.")
        response = client.chat.completions.create(
            model="gpt-4o",
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1,
            max_tokens=4090
        )
        logging.info("Successfully received negotiation analysis from GPT-4o.")
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        st.error(f"OpenAI APIã§ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        logging.error(f"Error during negotiation analysis: {e}")
        return None


def get_refined_report(original_report, user_instruction):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã«åŸºã¥ãã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿®æ­£ã™ã‚‹"""
    system_prompt = "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€æä¾›ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚å¿…ãšãƒ¬ãƒãƒ¼ãƒˆå…¨ä½“ã®æ§‹é€ ã‚’ç¶­æŒã—ãŸã¾ã¾ã€æŒ‡ç¤ºã•ã‚ŒãŸç®‡æ‰€ã®ã¿ã‚’ä¿®æ­£ã—ã€ä¿®æ­£å¾Œã®ãƒ¬ãƒãƒ¼ãƒˆå…¨æ–‡ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    user_prompt = f"""
### å…ƒã®ãƒ¬ãƒãƒ¼ãƒˆ:
{original_report}
### ä¿®æ­£æŒ‡ç¤º:
{user_instruction}
"""
    try:
        response = client.chat.completions.create(model="gpt-4o", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}])
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"ãƒ¬ãƒãƒ¼ãƒˆã®ä¿®æ­£ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"); return original_report

# -------------------------------------------------------------------
# 4. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (Wordãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ, DBæ“ä½œãªã©)
# -------------------------------------------------------------------
def format_timestamp(seconds):
    """ç§’ã‚’HH:MM:SSå½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹"""
    return str(timedelta(seconds=int(seconds)))

def create_minutes_docx(report_text):
    doc = Document()
    doc.add_heading('å•†è«‡è­°äº‹éŒ²', 0)
    lines = report_text.split('\n')
    for line in lines:
        line = line.strip()
        if line.startswith('### '):
            doc.add_heading(line.replace('### ', ''), level=2)
        elif line.startswith('* **'):
            p = doc.add_paragraph()
            parts = line.replace('* **', '').split('**:', 1)
            run = p.add_run(parts[0])
            run.bold = True
            if len(parts) > 1:
                p.add_run(":" + parts[1])
        elif line.startswith('* '):
            doc.add_paragraph(line.replace('* ', ''), style='List Bullet')
        elif line.strip():
            doc.add_paragraph(line)
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio.getvalue()

def create_analysis_docx(analysis_data, negotiation_info, transcript_display):
    doc = Document()
    doc.add_heading('AIäº¤æ¸‰åˆ†æãƒ¬ãƒãƒ¼ãƒˆ', 0)
    
    # åŸºæœ¬æƒ…å ±
    doc.add_paragraph(f"ä¼æ¥­å: {negotiation_info.get('client_company', 'N/A')}")
    doc.add_paragraph(f"å–¶æ¥­æ‹…å½“: {negotiation_info.get('sales_rep', 'N/A')}")
    doc.add_paragraph(f"æ—¥æ™‚: {negotiation_info.get('date', 'N/A')}")
    doc.add_paragraph()

    # ä¼šè©±ãƒãƒ©ãƒ³ã‚¹ã®å††ã‚°ãƒ©ãƒ•ã‚’è¿½åŠ 
    doc.add_heading('ä¼šè©±ãƒãƒ©ãƒ³ã‚¹', level=1)
    our_company_name = negotiation_info.get('sales_rep', '')
    all_speakers = list(set(item.get('speaker', '') for item in transcript_display))
    our_speaker_label = ''
    our_company_last_name = our_company_name.split(' ')[0][:2]
    for speaker in all_speakers:
        if our_company_last_name in speaker:
            our_speaker_label = speaker
            break
    
    our_company_words = 0
    client_words = 0
    if transcript_display:
        for item in transcript_display:
            word_count = len(re.findall(r'\w+', item.get('text', '')))
            if item.get('speaker', '') == our_speaker_label and our_speaker_label:
                our_company_words += word_count
            else:
                client_words += word_count
    
    total_words = our_company_words + client_words
    if total_words > 0:
        our_ratio = (our_company_words / total_words) * 100
        client_ratio = (client_words / total_words) * 100
        
        fig = go.Figure(data=[go.Pie(labels=['é¡§å®¢', 'å–¶æ¥­æ‹…å½“'], values=[client_ratio, our_ratio], hole=.3, marker_colors=['#636EFA', '#EF553B'])])
        fig.update_traces(textinfo='percent+label', textfont_size=14, hovertemplate='<b>%{label}</b>: %{value:.1f}%<extra></extra>')
        fig.update_layout(title_text='ä¼šè©±ãƒãƒ©ãƒ³ã‚¹', height=300, margin=dict(t=50, b=0, l=0, r=0), showlegend=False)
        
        chart_path = "temp_chart.png"
        fig.write_image(chart_path, scale=2)
        doc.add_picture(chart_path, width=Inches(5.0))
        os.remove(chart_path)

    # ç·åˆè©•ä¾¡
    overall = analysis_data.get('overall_score', {})
    doc.add_heading(f"ç·åˆè©•ä¾¡: {overall.get('score', 'N/A')}ç‚¹", level=1)
    doc.add_paragraph(overall.get('summary', ''))
    
    # äº¤æ¸‰å…¨ä½“ã®æµã‚Œ
    narrative = analysis_data.get('flow_narrative_analysis', {})
    doc.add_heading(f"äº¤æ¸‰å…¨ä½“ã®æµã‚Œ: {narrative.get('title', '')}", level=1)
    doc.add_paragraph(narrative.get('narrative_comment', ''))
    doc.add_paragraph(f"è‰¯ã‹ã£ãŸç‚¹: {narrative.get('strength_point', '')}")
    doc.add_paragraph(f"æ”¹å–„ã™ã¹ãç‚¹: {narrative.get('weakness_point', '')}")

    # å„ã‚¹ãƒ†ãƒ¼ã‚¸ã®è©³ç´°è©•ä¾¡
    doc.add_heading('ã‚»ãƒ¼ãƒ«ã‚¹ãƒ•ãƒ­ãƒ¼è©³ç´°è©•ä¾¡', level=1)
    flow = analysis_data.get('sales_flow_assessment', {})
    stage_map = {
        "rapport_building": "é–¢ä¿‚æ§‹ç¯‰", "problem_discovery": "èª²é¡Œç™ºè¦‹",
        "value_addition": "ä¾¡å€¤ææ¡ˆ", "closing": "åˆæ„å½¢æˆã¨ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°"
    }
    for key, stage_name in stage_map.items():
        stage_data = flow.get(key, {})
        if stage_data:
            doc.add_heading(f"{stage_name} (ã‚¹ã‚³ã‚¢: {stage_data.get('score', 'N/A')})", level=2)
            doc.add_paragraph(f"ã‚³ãƒ¡ãƒ³ãƒˆ: {stage_data.get('comment', '')}")
            p = doc.add_paragraph()
            p.add_run('æ ¹æ‹ ã®ç™ºè¨€: ').bold = True
            p.add_run(f"ã€Œ{stage_data.get('evidence_quote', '')}ã€").italic = True

    # æœ€ã‚‚é‡è¦ãªå­¦ã³
    learning = analysis_data.get('key_learning_point', {})
    doc.add_heading(f"ä»Šå›ã®å­¦ã³: {learning.get('title', '')}", level=1)
    doc.add_paragraph(learning.get('description', ''))
    p = doc.add_paragraph()
    p.add_run('è±¡å¾´çš„ãªä¼šè©±: ').bold = True
    p.add_run(f"ã€Œ{learning.get('evidence_quote', '')}ã€").italic = True

    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio.getvalue()


def save_report_to_db(negotiation_info, analysis_data, report_markdown, cleaned_transcript):
    """åˆ†æçµæœã¨æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹"""
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''
        INSERT INTO reports (timestamp, sales_rep, client_company, client_rep, report_date, analysis_json, report_markdown, cleaned_transcript)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    ''', (
        datetime.now().isoformat(), negotiation_info['sales_rep'], negotiation_info['client_company'],
        negotiation_info['client_rep'], negotiation_info['date'],
        json.dumps(analysis_data, ensure_ascii=False), report_markdown,
        json.dumps(cleaned_transcript, ensure_ascii=False)
    ))
    conn.commit()
    conn.close()
    logging.info(f"Report for {negotiation_info['client_company']} saved to database.")

# -------------------------------------------------------------------
# 5. UIæç”»: ã‚µã‚¤ãƒ‰ãƒãƒ¼
# -------------------------------------------------------------------

with st.sidebar:
    st.header("AIäº¤æ¸‰ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
    st.markdown("---")
    menu_items = {"creation": "å•†è«‡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ", "history": "éå»ã®ãƒ¬ãƒãƒ¼ãƒˆ", "feedback": "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"}
    
    for key, value in menu_items.items():
        if st.button(value, use_container_width=True, type="primary" if st.session_state.current_page == key else "secondary"):
            st.session_state.current_page = key
            if 'viewing_report_id' in st.session_state:
                del st.session_state['viewing_report_id']
            st.rerun()

# -------------------------------------------------------------------
# 6. UIæç”»: ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ (ãƒšãƒ¼ã‚¸åˆ‡ã‚Šæ›¿ãˆ)
# -------------------------------------------------------------------

if st.session_state.current_page == "creation":
    st.title("å•†è«‡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ")

    if st.session_state.analysis_stage != "initial":
        if st.button("æ–°ã—ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹"):
            st.session_state.confirm_reset = True
    
    if 'confirm_reset' not in st.session_state: st.session_state.confirm_reset = False
    
    if st.session_state.confirm_reset:
        placeholder = st.empty()
        with placeholder.container(border=True):
            st.warning("ç¾åœ¨ã®ä½œæ¥­å†…å®¹ã¯å¤±ã‚ã‚Œã¾ã™ã€‚æ–°ã—ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã‹ï¼Ÿ")
            col1, col2 = st.columns(2)
            if col1.button("ã¯ã„ã€ä½œæˆã™ã‚‹", use_container_width=True, type="primary"):
                reset_creation_page_state()
                st.session_state.confirm_reset = False
                placeholder.empty()
                st.rerun()
            if col2.button("ã„ã„ãˆ", use_container_width=True):
                st.session_state.confirm_reset = False
                placeholder.empty()
                st.rerun()

    if st.session_state.analysis_stage == "initial":
        with st.form("upload_form"):
            st.subheader("å•†è«‡æƒ…å ±ã®å…¥åŠ›ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            neg_date = st.date_input("å•†è«‡æ—¥", value=date.today())
            rep_names = ["ç”°ä¸­çœŸå¥ˆç¾", "æ¸¡è¾ºå¾¹", "å°æ—æ­å­", "æ–è—¤å­¦", "å·¥è—¤æ–°ä¸€"]
            sales_rep = st.selectbox("å–¶æ¥­æ‹…å½“è€…å", options=rep_names)
            client_company = st.text_input("é¡§å®¢ä¼æ¥­å", placeholder="æ ªå¼ä¼šç¤¾ãƒ‡ãƒ¢")
            client_rep = st.text_input("é¡§å®¢æ‹…å½“è€…å", placeholder="å•†è«‡ èŠ±å­")
            uploaded_file = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=['wav', 'mp3', 'm4a'])
            submitted = st.form_submit_button("åˆ†æã‚’é–‹å§‹ã™ã‚‹")
            if submitted:
                if not all([sales_rep, client_company, client_rep, uploaded_file]):
                    st.warning("ã™ã¹ã¦ã®é …ç›®ã‚’å…¥åŠ›ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                else:
                    st.session_state.negotiation_info = {"date": neg_date.strftime('%Yå¹´%mæœˆ%dæ—¥'), "sales_rep": sales_rep, "client_company": client_company, "client_rep": client_rep}
                    st.session_state.uploaded_file = uploaded_file
                    st.session_state.analysis_stage = 'processing'
                    st.rerun()

    if st.session_state.analysis_stage == 'processing':
        uploaded_file = st.session_state.get('uploaded_file')
        if uploaded_file:
            with st.status("AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒåˆ†æä¸­ã§ã™...", expanded=True) as status:
                raw_transcript_text = ""
                try:
                    status.write("ã‚¹ãƒ†ãƒƒãƒ—1/4: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ä¸­...")
                    audio_bytes = uploaded_file.getvalue()
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                        tmp.write(audio_bytes); temp_path = tmp.name
                    audio = AudioSegment.from_file(temp_path).set_frame_rate(16000).set_sample_width(2).set_channels(1)
                    wav_path = temp_path + ".wav"; audio.export(wav_path, format="wav")
                    
                    status.update(label="âœ… ã‚¹ãƒ†ãƒƒãƒ—1/4: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ã—ã¾ã—ãŸã€‚")
                    status.write("ã‚¹ãƒ†ãƒƒãƒ—2/4: è©±è€…ã‚’ç‰¹å®šä¸­...")
                    diarization_pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1", use_auth_token=HF_TOKEN)
                    if torch.cuda.is_available(): diarization_pipeline.to(torch.device("cuda"))
                    diarization = diarization_pipeline(wav_path)
                    
                    status.update(label="âœ… ã‚¹ãƒ†ãƒƒãƒ—2/4: è©±è€…ã‚’ç‰¹å®šã—ã¾ã—ãŸã€‚")
                    status.write("ã‚¹ãƒ†ãƒƒãƒ—3/4: æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œä¸­...")
                    device = "cuda" if torch.cuda.is_available() else "cpu"
                    whisper_model = whisper.load_model(WHISPER_MODEL, device=device)
                    transcription_result = whisper_model.transcribe(wav_path, word_timestamps=True, language="ja")
                    
                    status.update(label="âœ… ã‚¹ãƒ†ãƒƒãƒ—3/4: æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    status.write("ã‚¹ãƒ†ãƒƒãƒ—4/4: æ–‡å­—èµ·ã“ã—ã¨è©±è€…æƒ…å ±ã‚’çµåˆä¸­...")
                    word_timestamps = [word for segment in transcription_result['segments'] for word in segment['words']]
                    if word_timestamps:
                        speaker_turns = [{'start': turn.start, 'end': turn.end, 'speaker': speaker} for turn, _, speaker in diarization.itertracks(yield_label=True)]
                        for word in word_timestamps:
                            word_center = word['start'] + (word['end'] - word['start']) / 2
                            word['speaker'] = next((turn['speaker'] for turn in speaker_turns if turn['start'] <= word_center <= turn['end']), 'UNKNOWN')
                        
                        current_speaker, current_transcript, start_time = word_timestamps[0]['speaker'], "", word_timestamps[0]['start']
                        for word in word_timestamps:
                            if word['speaker'] != current_speaker:
                                raw_transcript_text += f"{current_speaker} ({format_timestamp(start_time)}): {current_transcript.strip()}\n"
                                current_speaker, current_transcript, start_time = word['speaker'], "", word['start']
                            current_transcript += word['word']
                        raw_transcript_text += f"{current_speaker} ({format_timestamp(start_time)}): {current_transcript.strip()}\n"

                    status.update(label="âœ… ã‚¹ãƒ†ãƒƒãƒ—4/4: çµåˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    status.write("GPT-4oã«ã‚ˆã‚‹æœ€çµ‚åˆ†æä¸­...")
                    analysis_result = get_negotiation_analysis(raw_transcript_text, st.session_state.negotiation_info)
                    
                    if analysis_result:
                        status.update(label="åˆ†æå®Œäº†ï¼", state="complete", expanded=False)
                        st.session_state.analysis_data = analysis_result
                        st.session_state.transcript_display = analysis_result.get('cleaned_transcript', [])
                        st.session_state.analysis_stage = 'done'
                        st.session_state.chat_history = [{"role": "assistant", "content": "ãƒ¬ãƒãƒ¼ãƒˆã¨AIã‚³ãƒ¼ãƒãƒ³ã‚°ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚"}]
                        st.rerun()
                    else:
                        status.update(label="åˆ†æå¤±æ•—", state="error")
                        st.error("åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚"); st.session_state.analysis_stage = 'initial'

                except Exception as e:
                    status.update(label="ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ", state="error")
                    st.error(f"éŸ³å£°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    logging.error(f"Error in audio processing: {e}")
                    st.session_state.analysis_stage = "initial"

                finally:
                    if 'temp_path' in locals() and temp_path and os.path.exists(temp_path): os.remove(temp_path)
                    if 'wav_path' in locals() and wav_path and os.path.exists(wav_path): os.remove(wav_path)

    if st.session_state.analysis_stage == 'done':
        analysis_data = st.session_state.analysis_data
        
        tab1, tab2, tab3 = st.tabs(["ğŸ“ è­°äº‹éŒ²ãƒ¬ãƒãƒ¼ãƒˆ", "ğŸ¤– AIã‚³ãƒ¼ãƒãƒ³ã‚°", "ğŸ—£ï¸ å…¨æ–‡æ–‡å­—èµ·ã“ã—"])

        with tab1:
            st.subheader("å¯¾è©±å‹ãƒ¬ãƒãƒ¼ãƒˆç·¨é›†")
            chat_container = st.container(height=200)
            with chat_container:
                for message in st.session_state.chat_history:
                    with st.chat_message(message["role"]):
                        st.markdown(message["content"])
            
            if prompt := st.chat_input("ãƒ¬ãƒãƒ¼ãƒˆã®ä¿®æ­£æŒ‡ç¤ºã‚’å…¥åŠ›"):
                st.session_state.chat_history.append({"role": "user", "content": prompt})
                with st.spinner("AIãŒãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿®æ­£ä¸­ã§ã™..."):
                    refined_report = get_refined_report(st.session_state.report_for_display, prompt)
                    st.session_state.report_for_display = refined_report
                st.session_state.chat_history.append({"role": "assistant", "content": "ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿®æ­£ã—ã¾ã—ãŸã€‚"})
                st.rerun()
            
            st.subheader("ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ")
            if not st.session_state.report_for_display:
                report_data = analysis_data.get('summary_report', {})
                overview = report_data.get('overview', {})
                attendees = overview.get('attendees', {})
                summary_items = report_data.get('summary', [])
                summary_text = "\n".join(f"* {item}" for item in summary_items) if isinstance(summary_items, list) else f"* {summary_items}"

                report_parts = [
                    f"### 1. å•†è«‡æ¦‚è¦", f"* **æ—¥æ™‚**: {overview.get('date', 'N/A')}", f"* **å‡ºå¸­è€…**:",
                    f"  * **{attendees.get('client_company', 'é¡§å®¢ä¼æ¥­')}**: {attendees.get('client_rep', 'N/A')}",
                    f"  * **å¼Šç¤¾**: {attendees.get('our_company', 'N/A')}",
                    f"### 2. æœ¬æ—¥ã®ç›®çš„ï¼ˆã‚¢ã‚¸ã‚§ãƒ³ãƒ€ï¼‰", f"* {report_data.get('agenda', 'N/A')}",
                    f"### 3. ä¸»è¦ãªè­°è«–ã®è¦ç´„", summary_text,
                    f"### 4. æ±ºå®šäº‹é …", "\n".join(f"* {item}" for item in report_data.get('decisions', ['ç‰¹ã«ãªã—'])),
                    f"### 5. ToDoï¼ˆãƒã‚¯ã‚¹ãƒˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼‰", "\n".join(f"* {item}" for item in report_data.get('todos', ['ç‰¹ã«ãªã—'])),
                    f"### 6. ç¢ºèªäº‹é …ãƒ»æ‡¸å¿µç‚¹", "\n".join(f"* {item}" for item in report_data.get('concerns', ['ç‰¹ã«ãªã—'])),
                ]
                st.session_state.report_for_display = "\n\n".join(report_parts)
            
            edited_report = st.text_area("ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ã‚’ç›´æ¥ç·¨é›†", st.session_state.report_for_display, height=400, label_visibility="collapsed")
            if edited_report != st.session_state.report_for_display:
                st.session_state.report_for_display = edited_report
                st.rerun()

        with tab2:
            st.subheader("AIã«ã‚ˆã‚‹äº¤æ¸‰åˆ†æ")
            overall = analysis_data.get('overall_score', {})
            narrative = analysis_data.get('flow_narrative_analysis', {})
            flow = analysis_data.get('sales_flow_assessment', {})
            learning = analysis_data.get('key_learning_point', {})

            our_company_name = st.session_state.negotiation_info.get('sales_rep', '')
            all_speakers = list(set(item.get('speaker', '') for item in st.session_state.transcript_display))
            our_speaker_label = ''
            our_company_last_name = our_company_name.split(' ')[0][:2]
            for speaker in all_speakers:
                if our_company_last_name in speaker:
                    our_speaker_label = speaker
                    break
            
            our_company_words = 0
            client_words = 0
            if st.session_state.transcript_display:
                for item in st.session_state.transcript_display:
                    word_count = len(re.findall(r'\w+', item.get('text', '')))
                    if item.get('speaker', '') == our_speaker_label and our_speaker_label:
                        our_company_words += word_count
                    else:
                        client_words += word_count
            
            total_words = our_company_words + client_words
            if total_words > 0:
                our_ratio = (our_company_words / total_words) * 100
                client_ratio = (client_words / total_words) * 100
                
                fig = go.Figure(data=[go.Pie(labels=['é¡§å®¢', 'å–¶æ¥­æ‹…å½“'], values=[client_ratio, our_ratio], hole=.3, marker_colors=['#636EFA', '#EF553B'])])
                fig.update_traces(textinfo='percent+label', textfont_size=14, hovertemplate='<b>%{label}</b>: %{value:.1f}%<extra></extra>')
                fig.update_layout(title_text='ä¼šè©±ãƒãƒ©ãƒ³ã‚¹', height=300, margin=dict(t=50, b=0, l=0, r=0), showlegend=False)
                st.plotly_chart(fig, use_container_width=True)

                if 20 <= our_ratio <= 40:
                    st.success("âœ”ï¸ **ç†æƒ³çš„ãªä¼šè©±ãƒãƒ©ãƒ³ã‚¹ã§ã™ã€‚** é¡§å®¢ã®è©±ã‚’ååˆ†ã«å¼•ãå‡ºã—ã€åŠ¹æœçš„ãªå¯¾è©±ãŒã§ãã¦ã„ã¾ã™ã€‚")
                elif our_ratio > 40:
                    st.warning("âš ï¸ **å–¶æ¥­æ‹…å½“è€…ã®ç™ºè©±ãŒå¤šã‚ã§ã™ã€‚** æ¬¡å›ã¯ã€è³ªå•ã‚’å¢—ã‚„ã—ã¦é¡§å®¢ãŒè©±ã™æ™‚é–“ã‚’ç¢ºä¿ã™ã‚‹ã“ã¨ã‚’æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚")
                else:
                    st.warning("âš ï¸ **é¡§å®¢ã®è©±ã‚’å¼•ãå‡ºã™ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚** ã‚ªãƒ¼ãƒ—ãƒ³ãªè³ªå•ã‚’æŠ•ã’ã‹ã‘ã€ã‚ˆã‚Šç©æ¥µçš„ã«å¯¾è©±ã‚’ãƒªãƒ¼ãƒ‰ã—ã¾ã—ã‚‡ã†ã€‚")


            st.metric("ç·åˆè©•ä¾¡ã‚¹ã‚³ã‚¢", f"{overall.get('score', 'N/A')} ç‚¹", delta=overall.get('summary', ''))
            st.markdown("---")
            
            st.markdown(f"##### äº¤æ¸‰å…¨ä½“ã®æµã‚Œï¼š {narrative.get('title', '')}")
            st.info(narrative.get('narrative_comment', ''))
            st.success(f"**è‰¯ã‹ã£ãŸç‚¹**: {narrative.get('strength_point', '')}")
            st.warning(f"**æ”¹å–„ã™ã¹ãç‚¹**: {narrative.get('weakness_point', '')}")
            st.markdown("---")

            st.markdown("##### ã‚»ãƒ¼ãƒ«ã‚¹ãƒ•ãƒ­ãƒ¼è©³ç´°è©•ä¾¡")
            stage_map = {
                "rapport_building": "é–¢ä¿‚æ§‹ç¯‰", "problem_discovery": "èª²é¡Œç™ºè¦‹",
                "value_addition": "ä¾¡å€¤ææ¡ˆ", "closing": "åˆæ„å½¢æˆã¨ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°"
            }
            for key, stage_name in stage_map.items():
                stage_data = flow.get(key, {})
                if stage_data:
                    with st.expander(f"**{stage_name}** (ã‚¹ã‚³ã‚¢: {stage_data.get('score', 'N/A')})"):
                        st.markdown(f"**ã‚³ãƒ¡ãƒ³ãƒˆ:** {stage_data.get('comment', '')}")
                        st.markdown(f"**æ ¹æ‹ ã®ç™ºè¨€:** *ã€Œ{stage_data.get('evidence_quote', '')}ã€*")
            
            st.markdown("---")
            st.markdown(f"##### ä»Šå›ã®å­¦ã³ï¼š {learning.get('title', '')}")
            st.info(f"{learning.get('description', '')}\n\n**è±¡å¾´çš„ãªä¼šè©±:** *ã€Œ{learning.get('evidence_quote', '')}ã€*")


        with tab3:
            st.subheader("å…¨æ–‡æ–‡å­—èµ·ã“ã—")
            transcript_container = st.container(height=600)
            with transcript_container:
                for item in st.session_state.transcript_display:
                    st.markdown(f"**{item.get('speaker', 'ä¸æ˜')}** ({item.get('start_time', '00:00:00')}): {item.get('text', '')}")

        st.sidebar.markdown("---")
        st.sidebar.subheader("ä¿å­˜ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        
        def save_current_report():
            if not st.session_state.get('report_saved', False):
                save_report_to_db(st.session_state.negotiation_info, st.session_state.analysis_data, st.session_state.report_for_display, st.session_state.transcript_display)
                st.session_state.report_saved = True
                st.toast("ãƒ¬ãƒãƒ¼ãƒˆã‚’å±¥æ­´ã«ä¿å­˜ã—ã¾ã—ãŸï¼")

        minutes_docx = create_minutes_docx(st.session_state.report_for_display)
        st.sidebar.download_button("è­°äº‹éŒ²ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", minutes_docx, "è­°äº‹éŒ².docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True, on_click=save_current_report)
        
        analysis_docx = create_analysis_docx(analysis_data, st.session_state.negotiation_info, st.session_state.transcript_display)
        st.sidebar.download_button("AIåˆ†æãƒ¬ãƒãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", analysis_docx, "AIåˆ†æãƒ¬ãƒãƒ¼ãƒˆ.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True, on_click=save_current_report)


elif st.session_state.current_page == "history":
    st.title("éå»ã®ãƒ¬ãƒãƒ¼ãƒˆä¸€è¦§")
    
    if 'viewing_report_id' in st.session_state and st.session_state.viewing_report_id is not None:
        report_id = st.session_state.get("viewing_report_id")
        conn = sqlite3.connect(DB_FILE)
        c = conn.cursor()
        c.execute("SELECT report_markdown, analysis_json, cleaned_transcript FROM reports WHERE id = ?", (report_id,))
        data = c.fetchone()
        conn.close()
        
        if data:
            report_markdown, analysis_json_str, cleaned_transcript_str = data
            
            st.subheader("ãƒ¬ãƒãƒ¼ãƒˆé–²è¦§")
            st.markdown(report_markdown)
            st.markdown("---")
            
            if st.button("ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç·¨é›†ã™ã‚‹", type="primary"):
                analysis_data = json.loads(analysis_json_str)
                st.session_state.analysis_data = analysis_data
                st.session_state.report_for_display = report_markdown
                overview = analysis_data.get('summary_report', {}).get('overview', {})
                attendees = overview.get('attendees', {})
                st.session_state.negotiation_info = {
                    "date": overview.get('date', 'N/A'),
                    "sales_rep": attendees.get('our_company', 'N/A'),
                    "client_company": attendees.get('client_company', 'N/A'),
                    "client_rep": attendees.get('client_rep', 'N/A')
                }
                st.session_state.transcript_display = json.loads(cleaned_transcript_str) if cleaned_transcript_str else []
                st.session_state.analysis_stage = "done"
                st.session_state.current_page = "creation"
                st.session_state.report_saved = True
                del st.session_state['viewing_report_id']
                st.rerun()

            if st.button("ãƒ¬ãƒãƒ¼ãƒˆä¸€è¦§ã«æˆ»ã‚‹"):
                del st.session_state['viewing_report_id']
                st.rerun()

    else:
        conn = sqlite3.connect(DB_FILE)
        c = conn.cursor()
        c.execute("SELECT id, report_date, sales_rep, client_company FROM reports ORDER BY timestamp DESC")
        all_reports = c.fetchall()
        conn.close()

        if not all_reports: st.info("ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        for report in all_reports:
            report_id, report_date, sales_rep, client_company = report
            with st.container(border=True):
                st.subheader(f"{client_company}æ§˜")
                st.write(f"æ‹…å½“: {sales_rep} | æ—¥ä»˜: {report_date}")
                if st.button("ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤ºã™ã‚‹", key=f"open_{report_id}"):
                    st.session_state.viewing_report_id = report_id
                    st.rerun()

elif st.session_state.current_page == "feedback":
    st.title("å–¶æ¥­æ‹…å½“è€…ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
    rep_names = ["ç”°ä¸­çœŸå¥ˆç¾", "æ¸¡è¾ºå¾¹", "å°æ—æ­å­", "æ–è—¤å­¦", "å·¥è—¤æ–°ä¸€"]
    selected_name = st.selectbox("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¦‹ã‚‹æ‹…å½“è€…ã‚’é¸æŠã—ã¦ãã ã•ã„", options=rep_names)
    
    if selected_name:
        conn = sqlite3.connect(DB_FILE)
        c = conn.cursor()
        c.execute("SELECT analysis_json, report_date, client_company FROM reports WHERE sales_rep = ? ORDER BY timestamp DESC", (selected_name,))
        user_reports_data = c.fetchall()
        conn.close()
        
        if not user_reports_data:
            st.warning(f"{selected_name}ã•ã‚“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            user_reports = [json.loads(r[0]) for r in user_reports_data]
            # ã€ãƒã‚°ä¿®æ­£ã€‘ã‚¹ã‚³ã‚¢ã‚’æ–‡å­—åˆ—ã‹ã‚‰æ•°å€¤ã«å¤‰æ›ã—ã¦è¨ˆç®—
            scores = [r.get('overall_score', {}).get('score', '0') for r in user_reports]
            valid_scores = []
            for s in scores:
                try:
                    valid_scores.append(int(s))
                except (ValueError, TypeError):
                    continue

            if valid_scores:
                avg_score = sum(valid_scores) / len(valid_scores)
                st.success(f"{len(user_reports)}ä»¶ã®å•†è«‡ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
                st.metric("å¹³å‡ç·åˆè©•ä¾¡ã‚¹ã‚³ã‚¢", f"{avg_score:.1f} ç‚¹")
                
                if avg_score >= 80:
                    st.info("ç´ æ™´ã‚‰ã—ã„æˆç¸¾ã§ã™ï¼å®‰å®šã—ã¦è³ªã®é«˜ã„äº¤æ¸‰ãŒã§ãã¦ã„ã¾ã™ã€‚")
                elif avg_score >= 60:
                    st.info("å®‰å®šã—ãŸäº¤æ¸‰ãŒã§ãã¦ã„ã¾ã™ã€‚æ¬¡ã¯ä»˜åŠ ä¾¡å€¤ææ¡ˆã®è³ªã‚’é«˜ã‚ã‚‹ã“ã¨ã‚’æ„è­˜ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                else:
                    st.warning("æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚ã¾ãšã¯é¡§å®¢ã®èª²é¡Œç™ºè¦‹ã«æ³¨åŠ›ã—ã€å…±æ„Ÿã‚’ç¤ºã™ã“ã¨ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚")
            else:
                st.warning("æœ‰åŠ¹ãªã‚¹ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

            st.markdown("---")
            st.subheader("éå»ã®AIã‚³ãƒ¼ãƒãƒ³ã‚°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¸€è¦§")

            for i, report_data in enumerate(user_reports_data):
                analysis_data = json.loads(report_data[0])
                report_date = report_data[1]
                client_company = report_data[2]
                
                overall = analysis_data.get('overall_score', {})
                narrative = analysis_data.get('flow_narrative_analysis', {})
                learning = analysis_data.get('key_learning_point', {})

                with st.expander(f"**{report_date}** - **{client_company}æ§˜** (ã‚¹ã‚³ã‚¢: {overall.get('score', 'N/A')})"):
                    st.markdown(f"**äº¤æ¸‰ã®è¦ç´„:** {overall.get('summary', 'N/A')}")
                    st.markdown(f"**äº¤æ¸‰ã®æµã‚Œ:** {narrative.get('narrative_comment', 'N/A')}")
                    st.markdown(f"**ä»Šå›ã®å­¦ã³:** {learning.get('title', 'N/A')}")
